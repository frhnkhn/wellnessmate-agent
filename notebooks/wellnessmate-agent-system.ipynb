{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# WellnessMate: Multi-Agent Health & Wellness Assistant\n\nThis project is my capstone submission for the Kaggle x Google AI Agents Intensive.","metadata":{}},{"cell_type":"markdown","source":"# WellnessMate: Multi-Agent Health & Wellness Assistant\n\nThis notebook implements **WellnessMate**, a multi-agent AI system that analyzes a person's wellness log (sleep, steps, mood, hydration, workouts, etc.) and generates simple, personalised recommendations for healthier habits.\n\nInstead of just doing one-off data analysis, WellnessMate uses **AI agents** to:\n\n- understand a user‚Äôs question (for example: *\"How is my sleep affecting my mood?\"*),\n- decide which analyses are needed,\n- run tools to compute trends and statistics from the data,\n- and finally transform those numbers into human-friendly advice.\n\nThis project is my capstone submission for the **Kaggle x Google AI Agents Intensive**.  \nThe goal is to clearly demonstrate how to apply the course concepts (agents, tools, memory, observability, evaluation, etc.) to a realistic use case: **supporting better health and wellness routines**.\n","metadata":{}},{"cell_type":"markdown","source":"## Key AI Agents Concepts Demonstrated\n\nIn this capstone project, I apply multiple core concepts from the **Kaggle x Google AI Agents Intensive**. The project demonstrates at least **five** of the required agentic capabilities:\n\n---\n\n### **1. Multi-Agent System (Sequential + Loop Behaviour)**  \nThis project uses a structured multi-agent architecture:\n\n- **PlannerAgent** ‚Äì understands the user‚Äôs query and creates an analysis plan.\n- **AnalyticsAgent** ‚Äì runs the actual data analysis using tools (statistics, trends, correlations).\n- **CoachAgent** ‚Äì turns numerical results into personalised wellness recommendations.\n\nThe agents run in a **sequential pipeline**:\n\n> User ‚Üí PlannerAgent ‚Üí AnalyticsAgent ‚Üí CoachAgent ‚Üí Final Output\n\nI also show a simple **loop-style behaviour**, where the system can run multiple iterations to update or refine recommendations with new data.\n\n---\n\n### **2. Tools (Custom Tools + Code Execution)**  \nThe agents do not directly manipulate the raw data.  \nInstead, they call a registry of **custom tools**, such as:\n\n- `filter_by_date()`\n- `compute_basic_stats()`\n- `compute_correlations()`\n- `recent_trend()`\n- (optional) `generate_simple_plot()` using Python execution\n\nThis follows the tool-calling pattern taught in the course, where agents ‚Äútake action‚Äù by calling tools rather than embedding all logic internally.\n\n---\n\n### **3. Sessions & Memory (Short-Term + Long-Term)**  \nThis system uses **two layers of memory**:\n\n- **Session memory**  \n  Stores the current conversation state and intermediate results.\n\n- **Long-term memory**  \n  Implemented as a simple JSON store that saves recurring wellness insights, such as patterns between sleep and mood.\n\nThis demonstrates how agents can use both **short-term session context** and **persistent long-term knowledge**.\n\n---\n\n### **4. Observability (Logging, Tracing, Metrics)**  \nThe system logs every major action into a shared **trace**, including:\n\n- which agent ran,\n- which tools were used,\n- timestamps for each step.\n\nI also track simple **metrics**:\n\n- number of tool calls,\n- runtime,\n- number of generated recommendations.\n\nThis reflects the observability practices taught in the course (logging, tracing, metrics).\n\n---\n\n### **5. Agent Evaluation**  \nI include lightweight evaluation checks:\n\n- verifying dataset loading,\n- checking that statistical tools produce expected outputs,\n- ensuring that at least one recommendation is generated for normal queries.\n\nThis shows a basic but clear approach to **agent quality evaluation**, as required in the capstone.\n","metadata":{}},{"cell_type":"markdown","source":"## System Architecture Overview\n\n### **1. High-Level Concept**\nThe idea behind WellnessMate is simple:\n\n> ‚ÄúGiven a user‚Äôs daily wellness logs (sleep, steps, mood, hydration, workouts),  \n> how can an AI agent system understand the user‚Äôs questions, analyze their wellness patterns,  \n> and suggest small, personalised improvements?‚Äù\n\nRather than using a single large script, the project uses multiple collaborating **agents**, each responsible for part of the workflow.\n\n---\n\n### **2. Agents in the System**\n\n#### **1. PlannerAgent**\n- Reads the user‚Äôs natural language question.  \n- Determines what type of analysis is needed (trends, correlations, general overview, etc.).  \n- Produces a simple **plan** describing which steps and tools should run.\n\n#### **2. AnalyticsAgent**\n- Takes the plan from the PlannerAgent.  \n- Uses tools to analyze the wellness dataset:\n  - compute basic statistics,\n  - extract recent trends,\n  - compute correlations between variables.\n\n#### **3. CoachAgent**\n- Takes the analysis results.  \n- Converts numerical data into practical, personalised wellness recommendations.  \n- Stores useful insights into **long-term memory** (Memory Bank style).\n\nTogether, these agents work in a **sequential pipeline**:\n> Planner ‚Üí Analytics ‚Üí Coach\n\n---\n\n### **3. Tools Layer**\nTo follow the agentic pattern from the course, the system uses **tools** instead of embedding logic directly in agents.\n\nExamples of custom tools:\n- `compute_basic_stats()` ‚Äì mean/min/max for each metric  \n- `compute_correlations()` ‚Äì checks relationships (e.g., sleep ‚Üî mood)  \n- `recent_trend()` ‚Äì extracts the last 7/14/30 days of data  \n- `filter_by_date()` ‚Äì optional date filtering  \n- `generate_plot()` ‚Äì code-based tool to create charts\n\nAgents call these tools through a `tool_registry`, which imitates an MCP-style tool discovery mechanism.\n\n---\n\n### **4. Memory Layer**\n\n#### **Session Memory**\n- Tracks the current conversation.\n- Stores partial results within a single agent run.\n\n#### **Long-Term Memory**\n- A simple JSON file (`wellness_memory.json`).\n- Stores repeated or meaningful insights so the agent can re-use them across sessions.\n- Demonstrates the concept of a lightweight **Memory Bank**.\n\n---\n\n### **5. Observability & Evaluation**\n\nThe system includes:\n\n- **Logging & Tracing:**  \n  Every agent action is recorded in a trace list with timestamps.\n\n- **Metrics:**  \n  For each run, the system records:\n  - tool calls count,\n  - runtime,\n  - number of recommendations generated.\n\n- **Evaluation Checks:**  \n  Small tests verify:\n  - the dataset loads,\n  - the tools return expected outputs,\n  - the agent produces suggestions.\n\nThese elements support debugging, transparency, and quality control, aligning with the course‚Äôs best practices for **agent observability**.\n\n---\n\n### **6. End-to-End Flow**\n\n> User query  \n> ‚Üí PlannerAgent creates a plan  \n> ‚Üí AnalyticsAgent executes tools  \n> ‚Üí CoachAgent generates personalised recommendations  \n> ‚Üí Logs, memory updates, and metrics recorded  \n> ‚Üí Final wellness insights returned\n\nThis complete flow showcases how an AI agentic system can analyze wellness data and provide user-friendly, actionable insights.\n","metadata":{}},{"cell_type":"markdown","source":"## Dataset Loading & Tool Definitions\n\nIn this section, I load the wellness dataset and define the set of **custom tools** that the agents will use.\n\nThese tools follow the action-taking pattern taught in the course:  \ninstead of hardcoding logic inside the agent, each step of work is done by a separate tool function.\n\nThe tools include:\n\n- filtering by date  \n- computing basic statistics  \n- computing correlations  \n- extracting recent trends  \n- (optional) generating plots\n\nAll tools are stored in a `tool_registry` so the agents can ‚Äúcall‚Äù them by name,  \nsimilar to how AI agents interact with MCP-style tools.\n","metadata":{}},{"cell_type":"code","source":"# --- Imports ---\nimport pandas as pd\nimport numpy as np\nimport json\nimport time\nfrom pathlib import Path\n\n# --- Load the dataset ---\n\n# IMPORTANT:\n# For now, we create a placeholder DataFrame so the notebook runs.\n# Later, if you upload a real dataset to Kaggle, you can replace this part.\n\ndata_example = {\n    \"date\": pd.date_range(start=\"2024-01-01\", periods=30, freq=\"D\"),\n    \"sleep_hours\": np.random.uniform(4, 9, 30),\n    \"steps\": np.random.randint(2000, 12000, 30),\n    \"mood\": np.random.randint(1, 6, 30),  # 1 to 5 rating\n    \"water_glasses\": np.random.randint(3, 10, 30),\n    \"workout_minutes\": np.random.randint(0, 60, 30),\n}\n\ndf = pd.DataFrame(data_example)\n\ndf.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Custom Tools\n\nThese tools perform the core data operations.  \nThe agents (Planner, Analytics, Coach) will call these tools by name via a `tool_registry`.\n\nEach tool is designed to be:\n\n- simple  \n- reusable  \n- separable from agent logic  \n\nThis is exactly the tool-based design encouraged in the course.\n","metadata":{}},{"cell_type":"code","source":"# --- CUSTOM TOOLS ---\n\ndef filter_by_date(df, start_date=None, end_date=None):\n    data = df.copy()\n    if start_date:\n        data = data[data[\"date\"] >= pd.to_datetime(start_date)]\n    if end_date:\n        data = data[data[\"date\"] <= pd.to_datetime(end_date)]\n    return data\n\n\ndef compute_basic_stats(df):\n    metrics = [\"sleep_hours\", \"steps\", \"mood\", \"water_glasses\", \"workout_minutes\"]\n    stats = {}\n\n    for col in metrics:\n        if col in df.columns:\n            stats[col] = {\n                \"mean\": float(df[col].mean()),\n                \"min\": float(df[col].min()),\n                \"max\": float(df[col].max()),\n            }\n    return stats\n\n\ndef compute_correlations(df):\n    numeric_df = df.select_dtypes(include=[np.number])\n    if numeric_df.shape[1] < 2:\n        return {}\n    corr = numeric_df.corr()\n    return corr.to_dict()\n\n\ndef recent_trend(df, days=14):\n    if df.empty:\n        return df\n    cutoff = df[\"date\"].max() - pd.Timedelta(days=days)\n    return df[df[\"date\"] >= cutoff]\n\n\ndef generate_simple_plot(df):\n    # Plot tool: visual code execution-style tool\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=(10, 4))\n    plt.plot(df[\"date\"], df[\"sleep_hours\"])\n    plt.title(\"Sleep Trend Over Time\")\n    plt.xlabel(\"Date\")\n    plt.ylabel(\"Sleep Hours\")\n    plt.tight_layout()\n    plt.show()\n\n\n# --- TOOL REGISTRY (MCP-like pattern) ---\ntool_registry = {\n    \"filter_by_date\": filter_by_date,\n    \"compute_basic_stats\": compute_basic_stats,\n    \"compute_correlations\": compute_correlations,\n    \"recent_trend\": recent_trend,\n    \"generate_simple_plot\": generate_simple_plot,\n}\n\ntool_registry\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Session Memory, Long-Term Memory & Logging\n\nTo make this system feel more like a real agent (not just a script),  \nI add:\n\n- **Session memory** ‚Äì stores the current conversation and intermediate results.\n- **Long-term memory** ‚Äì a simple JSON file that stores important wellness insights\n  across runs (Memory Bank style).\n- **Logging / tracing** ‚Äì records which agent or tool did what, and when.\n\nThese structures will be used by the agents in later sections to:\n\n- remember past insights,\n- debug what happened in a run,\n- and support multi-turn conversations.\n","metadata":{}},{"cell_type":"code","source":"# --- SESSION MEMORY ---\n\n# This will store the messages / events for the current run.\nsession_history = []\n\n# --- LONG-TERM MEMORY (Memory Bank style) ---\n\nMEMORY_FILE = Path(\"wellness_memory.json\")\n\ndef load_long_term_memory():\n    \"\"\"Load long-term wellness insights from disk (if any).\"\"\"\n    if MEMORY_FILE.exists():\n        try:\n            return json.loads(MEMORY_FILE.read_text())\n        except json.JSONDecodeError:\n            # If file is corrupted, start fresh\n            return []\n    return []\n\ndef save_long_term_memory(memory):\n    \"\"\"Save long-term wellness insights to disk.\"\"\"\n    MEMORY_FILE.write_text(json.dumps(memory, indent=2))\n\nlong_term_memory = load_long_term_memory()\n\ndef add_insight_to_memory(text):\n    \"\"\"Append a new insight to the long-term memory.\"\"\"\n    entry = {\n        \"insight\": text,\n        \"ts\": time.time()\n    }\n    long_term_memory.append(entry)\n    save_long_term_memory(long_term_memory)\n    return entry\n\n# --- LOGGING / TRACING ---\n\ntrace = []\n\ndef log_event(agent, message):\n    \"\"\"Record an event in the trace log.\"\"\"\n    event = {\n        \"ts\": time.time(),\n        \"agent\": agent,\n        \"message\": message\n    }\n    trace.append(event)\n    return event\n\n# Quick sanity check\nlog_event(\"system\", \"Memory and logging initialised.\")\nlong_term_memory[:3], trace[:1]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Agent Definitions: Planner, Analytics, Coach\n\nNow that the tools, memory, and logging are in place,  \nI define three simple agents:\n\n1. **PlannerAgent** ‚Äì reads the user‚Äôs question and decides what kind of analysis is needed.\n2. **AnalyticsAgent** ‚Äì calls the tools to analyse the wellness data.\n3. **CoachAgent** ‚Äì turns the analysis into human-friendly wellness tips and stores insights in long-term memory.\n\nThese agents are not ‚Äúsmart‚Äù by themselves (no complex NLP here).  \nInstead, they follow simple rule-based logic to simulate how an LLM-powered agent would:\n\n- decide which tools to use,\n- interpret data,\n- and generate helpful recommendations.\n","metadata":{}},{"cell_type":"markdown","source":"## PlannerAgent ‚Äì \nReads the user‚Äôs question and decides what kind of analysis is needed.","metadata":{}},{"cell_type":"code","source":"# --- PLANNER AGENT ---\n\ndef planner_agent(user_query: str):\n    \"\"\"\n    Very simple planner:\n    - Looks at the user's text.\n    - Decides which analysis steps (tools) to run.\n    - Returns a 'plan' dictionary.\n    \"\"\"\n    log_event(\"planner\", f\"Received query: {user_query}\")\n\n    q = user_query.lower()\n    plan = {\"steps\": []}\n\n    # If the user mentions \"trend\" or \"recent\", focus on recent_trend + stats\n    if \"trend\" in q or \"recent\" in q or \"last\" in q:\n        plan[\"steps\"].append(\"recent_trend\")\n        plan[\"steps\"].append(\"basic_stats\")\n\n    # If the user talks about \"relationship\", \"effect\", \"impact\", use correlations\n    if \"relationship\" in q or \"effect\" in q or \"impact\" in q or \"correlat\" in q:\n        plan[\"steps\"].append(\"correlations\")\n\n    # If they mention specific metrics\n    focus_metrics = []\n    if \"sleep\" in q:\n        focus_metrics.append(\"sleep_hours\")\n    if \"mood\" in q:\n        focus_metrics.append(\"mood\")\n    if \"steps\" in q or \"walk\" in q:\n        focus_metrics.append(\"steps\")\n\n    if focus_metrics:\n        plan[\"focus_metrics\"] = focus_metrics\n\n    # Default behaviour: if no specific keyword found, just do basic overview\n    if not plan[\"steps\"]:\n        plan[\"steps\"] = [\"basic_stats\"]\n\n    log_event(\"planner\", f\"Plan created: {plan}\")\n    return plan\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## AnalyticsAgent ‚Äì \nCalls the tools to analyse the wellness data.","metadata":{}},{"cell_type":"code","source":"# --- ANALYTICS AGENT ---\n\ndef analytics_agent(plan, df):\n    \"\"\"\n    Runs the actual data analysis based on the plan.\n    Uses the tools defined earlier.\n    \"\"\"\n    log_event(\"analytics\", f\"Starting analytics with plan: {plan}\")\n    analysis_result = {}\n\n    # Start with full dataset\n    data_for_analysis = df.copy()\n\n    # If the plan includes recent trend, reduce to last N days\n    if \"recent_trend\" in plan.get(\"steps\", []):\n        data_for_analysis = tool_registry[\"recent_trend\"](data_for_analysis, days=14)\n        analysis_result[\"recent_data_rows\"] = int(len(data_for_analysis))\n\n    # Always compute basic stats if requested\n    if \"basic_stats\" in plan.get(\"steps\", []):\n        analysis_result[\"basic_stats\"] = tool_registry[\"compute_basic_stats\"](data_for_analysis)\n\n    # Compute correlations if requested\n    if \"correlations\" in plan.get(\"steps\", []):\n        analysis_result[\"correlations\"] = tool_registry[\"compute_correlations\"](data_for_analysis)\n\n    # Save which metrics we were focusing on (if any)\n    if \"focus_metrics\" in plan:\n        analysis_result[\"focus_metrics\"] = plan[\"focus_metrics\"]\n\n    log_event(\"analytics\", f\"Analytics result keys: {list(analysis_result.keys())}\")\n    return analysis_result\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## CoachAgent ‚Äì \nTurns the analysis into human-friendly wellness tips and stores insights in long-term memory.","metadata":{}},{"cell_type":"code","source":"# --- COACH AGENT ---\n\ndef coach_agent(analysis_result, user_query: str):\n    \"\"\"\n    Turns numbers into simple wellness advice.\n    Uses heuristic rules (if avg sleep < 7 -> suggest more sleep, etc.).\n    Also writes a short summary to long-term memory.\n    \"\"\"\n    log_event(\"coach\", \"Generating coaching tips\")\n\n    tips = []\n    stats = analysis_result.get(\"basic_stats\", {})\n    focus = analysis_result.get(\"focus_metrics\", [])\n\n    sleep_stats = stats.get(\"sleep_hours\")\n    mood_stats = stats.get(\"mood\")\n    water_stats = stats.get(\"water_glasses\")\n    steps_stats = stats.get(\"steps\")\n    workout_stats = stats.get(\"workout_minutes\")\n\n    # Simple rules for sleep\n    if sleep_stats:\n        if sleep_stats[\"mean\"] < 7:\n            tips.append(\"Try to aim for at least 7 hours of sleep on most nights.\")\n        else:\n            tips.append(\"Your average sleep duration looks good. Focus on keeping a consistent sleep schedule.\")\n\n    # Simple rules for mood\n    if mood_stats:\n        if mood_stats[\"mean\"] <= 3:\n            tips.append(\"Your average mood is on the lower side. Consider relaxing activities before bed and short breaks during the day.\")\n        else:\n            tips.append(\"Your average mood looks fairly positive. Keep up habits that make you feel good.\")\n\n    # Simple rules for water\n    if water_stats:\n        if water_stats[\"mean\"] < 8:\n            tips.append(\"Try increasing your water intake towards 8 glasses per day.\")\n        else:\n            tips.append(\"Your water intake looks good. Stay hydrated, especially on active days.\")\n\n    # Simple rules for steps\n    if steps_stats:\n        if steps_stats[\"mean\"] < 6000:\n            tips.append(\"Your daily steps are a bit low. Try adding short walks after meals or using stairs more often.\")\n        else:\n            tips.append(\"Your step count is healthy. You can maintain this level or add variety with different types of movement.\")\n\n    # Simple rules for workout\n    if workout_stats:\n        if workout_stats[\"mean\"] < 20:\n            tips.append(\"You could benefit from a bit more intentional exercise. Even 20‚Äì30 minutes a day can help.\")\n        else:\n            tips.append(\"You are getting a decent amount of workout time. Keep going and listen to your body's signals.\")\n\n    # If for some reason no tips were generated\n    if not tips:\n        tips.append(\"Data is limited or unclear, but try to maintain regular sleep, hydration, and gentle movement each day.\")\n\n    high_level_summary = \"These suggestions are based on your recent wellness data and simple heuristic rules (not medical advice).\"\n\n    # Store a short summary in long-term memory\n    memory_text = f\"Generated {len(tips)} wellness tips for query: '{user_query[:50]}...'\"\n    add_insight_to_memory(memory_text)\n\n    coaching = {\n        \"summary\": high_level_summary,\n        \"tips\": tips,\n    }\n\n    log_event(\"coach\", f\"Generated {len(tips)} tips\")\n    return coaching\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Quick Test","metadata":{}},{"cell_type":"code","source":"# Quick test for the three agents together\ntest_query = \"Show me recent trends and how my sleep and mood are doing.\"\nplan = planner_agent(test_query)\nanalysis = analytics_agent(plan, df)\ncoaching = coach_agent(analysis, test_query)\n\nplan, list(analysis.keys()), coaching[\"summary\"], len(coaching[\"tips\"])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Orchestrator: End-to-End Agent Flow\n\nIn this section, I connect all the pieces into a single function:\n\n> `run_wellness_agent(user_query)`\n\nThis function:\n\n1. Records the start of a new session.\n2. Calls **PlannerAgent** to create a plan.\n3. Calls **AnalyticsAgent** to run the tools and analyse the data.\n4. Calls **CoachAgent** to generate wellness tips.\n5. Logs all important events into the trace.\n6. Computes simple **metrics** (runtime, number of tips, etc.).\n7. Returns a structured result that can be used in any interface (CLI, web app, etc.).\n\nThis is similar to how a deployed agent endpoint would work in a real system.\n","metadata":{}},{"cell_type":"code","source":"# --- ORCHESTRATOR ---\n\ndef run_wellness_agent(user_query: str):\n    \"\"\"\n    Run the full WellnessMate pipeline:\n    - planner_agent -> analytics_agent -> coach_agent\n    - track session history, trace, and basic metrics\n    \"\"\"\n    # Use global variables defined earlier\n    global trace\n    trace = []  # reset trace for this run\n\n    start_time = time.time()\n\n    # Save user message in session memory\n    session_history.append({\"role\": \"user\", \"content\": user_query})\n\n    log_event(\"system\", \"Starting new wellness agent run\")\n\n    # 1. Planner\n    plan = planner_agent(user_query)\n\n    # 2. Analytics\n    analysis_result = analytics_agent(plan, df)\n\n    # 3. Coach\n    coaching = coach_agent(analysis_result, user_query)\n\n    end_time = time.time()\n    runtime = end_time - start_time\n\n    # --- METRICS ---\n    tool_calls_estimate = 0\n    # Very rough estimate: count keys that came from tools\n    if \"basic_stats\" in analysis_result:\n        tool_calls_estimate += 1\n    if \"correlations\" in analysis_result:\n        tool_calls_estimate += 1\n    if \"recent_data_rows\" in analysis_result:\n        tool_calls_estimate += 1\n\n    metrics = {\n        \"runtime_seconds\": round(runtime, 3),\n        \"estimated_tool_calls\": tool_calls_estimate,\n        \"tips_count\": len(coaching.get(\"tips\", [])),\n    }\n\n    log_event(\"system\", f\"Run finished in {metrics['runtime_seconds']} seconds\")\n\n    # Final structured response\n    response = {\n        \"user_query\": user_query,\n        \"plan\": plan,\n        \"analysis_result\": analysis_result,\n        \"coaching\": coaching,\n        \"metrics\": metrics,\n        \"trace\": trace,\n    }\n    return response\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Demo: Example Wellness Queries\n\nIn this section, I run the full `run_wellness_agent()` pipeline on a few example queries to show how the system behaves.\n\nThese examples simulate how a user might interact with the agent:\n\n- asking about overall wellness,\n- asking specifically about sleep and mood,\n- asking about energy or activity.\n","metadata":{}},{"cell_type":"code","source":"# --- DEMO RUNS ---\n\ndemo_queries = [\n    \"Give me an overview of my recent wellness.\",\n    \"Show me recent trends and how my sleep is affecting my mood.\",\n    \"How can I improve my energy based on my data?\",\n]\n\ndemo_results = []\n\nfor q in demo_queries:\n    print(\"=\" * 80)\n    print(\"USER QUERY:\", q)\n    result = run_wellness_agent(q)\n    demo_results.append(result)\n\n    print(\"Plan:\", result[\"plan\"])\n    print(\"Metrics:\", result[\"metrics\"])\n    print(\"Summary:\", result[\"coaching\"][\"summary\"])\n    print(\"Number of tips:\", len(result[\"coaching\"][\"tips\"]))\n    print(\"Example tip:\", result[\"coaching\"][\"tips\"][0] if result[\"coaching\"][\"tips\"] else \"No tips\")\n    print()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Show the trace of the last run to demonstrate logging & tracing\nprint(\"Trace for last run:\")\nfor event in demo_results[-1][\"trace\"]:\n    print(f\"[{event['agent']}] {event['message']}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Agent Evaluation\n\nTo make sure the agent system is not just \"running\" but also **behaving sensibly**,  \nI include a small **evaluation section**.\n\nThe goal here is not to build a perfect, production-grade evaluation suite,  \nbut to demonstrate the core ideas from the AI Agents Intensive:\n\n- sanity checks on the **data**,\n- sanity checks on the **tools**,\n- sanity checks on the **end-to-end agent behaviour**.\n\nI use a few lightweight tests to verify that:\n\n1. The dataset loads and is not empty.\n2. The statistics tool returns values for key metrics (e.g. `sleep_hours`).\n3. The full `run_wellness_agent()` pipeline can:\n   - run without errors,\n   - produce at least one wellness tip for a normal query.\n","metadata":{}},{"cell_type":"code","source":"# --- AGENT EVALUATION FUNCTIONS ---\n\ndef test_dataset_not_empty(df):\n    \"\"\"Check that the dataset loaded and has at least one row.\"\"\"\n    return not df.empty\n\ndef test_basic_stats_contains_sleep(df):\n    \"\"\"Check that the basic stats tool returns an entry for sleep_hours.\"\"\"\n    stats = compute_basic_stats(df)\n    return \"sleep_hours\" in stats and \"mean\" in stats[\"sleep_hours\"]\n\ndef test_agent_produces_tips():\n    \"\"\"Check that the full pipeline produces at least one tip.\"\"\"\n    sample_query = \"Give me an overview of my recent wellness.\"\n    result = run_wellness_agent(sample_query)\n    tips = result[\"coaching\"].get(\"tips\", [])\n    return len(tips) > 0\n\ndef evaluate_system(df):\n    \"\"\"Run all evaluation tests and return a summary dict.\"\"\"\n    results = {}\n\n    results[\"dataset_not_empty\"] = test_dataset_not_empty(df)\n    results[\"basic_stats_contains_sleep\"] = test_basic_stats_contains_sleep(df)\n    results[\"agent_produces_tips\"] = test_agent_produces_tips()\n\n    return results\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- RUN EVALUATION ---\n\nevaluation_results = evaluate_system(df)\nevaluation_results\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Agent Evaluation Results:\")\nfor name, passed in evaluation_results.items():\n    status = \"PASS ‚úÖ\" if passed else \"FAIL ‚ùå\"\n    print(f\"- {name}: {status}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prototype ‚Üí Production: How This Agent Could Be Deployed\n\nSo far, this notebook shows **WellnessMate** as a prototype:  \neverything runs inside one Jupyter notebook.\n\nIn a real-world scenario, the same agent system could be deployed so that\nother applications (web apps, mobile apps, chat interfaces) can call it.\n\n---\n\n### 1. Single Entry Point: `run_wellness_agent()`\n\nThe key design choice in this project is the function:\n\n```python\nrun_wellness_agent(user_query: str) -> dict\n","metadata":{}},{"cell_type":"markdown","source":"# Final Summary\n\n**WellnessMate** is a complete multi-agent system built as part of the  \n**Kaggle x Google AI Agents Intensive Capstone Project**.\n\nThis notebook demonstrates:\n\n### ‚úÖ 1. Multi-Agent System\n- **PlannerAgent**  \n- **AnalyticsAgent**  \n- **CoachAgent**  \nEach agent has a clear role and they work together in a sequential pipeline.\n\n### ‚úÖ 2. Tool Usage\nCustom tools handle:\n- statistics\n- correlations\n- trends\n- plotting  \nTools are managed via a `tool_registry`, following agentic tool-calling patterns.\n\n### ‚úÖ 3. Memory & Sessions\n- **Session memory** to track the conversation.\n- **Long-term memory** using a JSON file (`wellness_memory.json`).\n\n### ‚úÖ 4. Observability\n- Every major action is logged (agent name + message + timestamp).\n- A trace is stored and printed to inspect the agent workflow.\n- Simple runtime + tool call metrics computed for each query.\n\n### ‚úÖ 5. Agent Evaluation\nLightweight evaluation ensures:\n- dataset is valid,\n- tools work,\n- the full agent pipeline generates useful tips.\n\n### üöÄ Why This Matters\nThis project shows how AI agents can analyze personal wellness data  \nand generate personalised insights using:\n- tools,\n- memory,\n- agent orchestration,\n- and human-readable outputs.\n\nIt also demonstrates how such a system can scale from a **prototype**  \n(notebook) into a **production-ready backend agent** with minor adjustments.\n\n---\n\n### üéâ End of Notebook\nThanks for reviewing my capstone project!\n","metadata":{}}]}